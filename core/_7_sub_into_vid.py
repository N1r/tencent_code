import os
import subprocess
import time
import sys
import platform
import cv2
import re
import numpy as np
from core._1_ytdlp import find_video_files
from core.utils import * # å‡è®¾ rprint å’Œ load_key åœ¨è¿™é‡Œ

# ============= 1. å…¨å±€é…ç½®åŒºåŸŸ =============

# å­—ä½“é…ç½®
FONT_NAME = 'Arial'
TRANS_FONT_NAME = 'HYWenHei' 

if platform.system() == 'Linux':
    FONT_NAME = 'Arial'
    TRANS_FONT_NAME = 'HYWenHei'
elif platform.system() == 'Darwin':
    FONT_NAME = 'Arial Unicode MS'
    TRANS_FONT_NAME = 'HYWenHei'

# é¢œè‰²å®šä¹‰
COLOR_WHITE = '&HFFFFFF'
COLOR_ORANGE = '&H0000A5FF' # é²œè‰³æ©™è‰²
COLOR_BLACK = '&H00000000'

# --- [æ¨¡å¼ A: æ¨ªå±åŒè¯­æ ·å¼] ---
H_SRC_FONT_SIZE = 14
H_TRANS_FONT_SIZE = 24 
H_SRC_MARGIN_V = 20
H_TRANS_MARGIN_V = 65
H_WRAP_LIMIT = 20          

# --- [æ¨¡å¼ B: çŸ­è§†é¢‘ç«–å±å•ä¸­æ–‡æ ·å¼] ---
V_TRANS_FONT_SIZE = 12  
V_TRANS_MARGIN_V = 55     
V_TRANS_BACK_COLOR = '&H99000000' 
V_WRAP_LIMIT = 10           

# æ–‡ä»¶è·¯å¾„
OUTPUT_DIR = "output"
OUTPUT_VIDEO = f"{OUTPUT_DIR}/output_sub.mp4"
SRC_SRT = f"{OUTPUT_DIR}/src.srt"
TRANS_SRT = f"{OUTPUT_DIR}/trans.srt"
WRAPPED_SRT = f"{OUTPUT_DIR}/trans_wrapped.srt"
LOGO_PATH = r"core/logo.png"

# ============= 2. æ ¸å¿ƒè¾…åŠ©é€»è¾‘ =============

def wrap_text_logic(text, limit):
    """æ‰‹åŠ¨ç¡¬æ¢è¡Œé€»è¾‘"""
    text = text.replace('\n', ' ').strip()
    if len(text) <= limit:
        return text
    lines = [text[i:i + limit] for i in range(0, len(text), limit)]
    return "\\N".join(lines)

def process_srt_wrapping(input_srt, output_srt, limit):
    """é¢„å¤„ç†SRTæ–‡ä»¶è¿›è¡Œæ¢è¡Œ"""
    if not os.path.exists(input_srt):
        return False
    with open(input_srt, 'r', encoding='utf-8') as f:
        content = f.read()
    
    pattern = re.compile(r'(\d+\n\d{2}:\d{2}:\d{2},\d{3} --> \d{2}:\d{2}:\d{2},\d{3}\n)(.*?)(?=\n\n|\n$|$)', re.DOTALL)
    def replace_func(match):
        return match.group(1) + wrap_text_logic(match.group(2), limit)
    
    new_content = pattern.sub(replace_func, content)
    with open(output_srt, 'w', encoding='utf-8') as f:
        f.write(new_content)
    return True

def build_style(font_size, font_name, font_color, outline_color, outline_width, back_color, margin_v, margin_lr=30):
    """ç”Ÿæˆ ASS æ ·å¼å­—ç¬¦ä¸²"""
    return (
        f"FontSize={font_size},FontName={font_name},"
        f"PrimaryColour={font_color},OutlineColour={outline_color},"
        f"OutlineWidth={outline_width},BackColour={back_color},"
        f"BorderStyle=4,Alignment=2,MarginV={margin_v},"
        f"Bold=1,Spacing=1.5,Shadow=0,MarginL={margin_lr},MarginR={margin_lr}"
    )

def check_gpu_available():
    try:
        result = subprocess.run(['ffmpeg', '-encoders'], capture_output=True, text=True)
        return 'h264_nvenc' in result.stdout
    except:
        return False

# ============= 3. ä¸»é€»è¾‘ =============

def merge_subtitles_to_video():
    # 1. è·å–è§†é¢‘å¹¶åˆ†ææ¯”ä¾‹
    video_file = find_video_files()
    if not video_file or not os.path.exists(video_file):
        rprint("[bold red]âŒ æœªæ‰¾åˆ°è¾“å…¥è§†é¢‘æ–‡ä»¶ã€‚[/bold red]")
        return

    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    cap = cv2.VideoCapture(video_file)
    orig_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    orig_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    cap.release()

    is_vertical = orig_h > orig_w
    
    # --- å¼ºåˆ¶åˆ†è¾¨ç‡è®¾å®š ---
    if is_vertical:
        target_w, target_h = 1080, 1920
        rprint(f"ğŸ“± ç«–å±æ¨¡å¼: å¼ºåˆ¶è¾“å‡º [bold cyan]1080x1920[/bold cyan]")
    else:
        target_w, target_h = 1920, 1080
        rprint(f"ğŸ’» æ¨ªå±æ¨¡å¼: å¼ºåˆ¶è¾“å‡º [bold cyan]1920x1080[/bold cyan]")

    # 2. å­—å¹•æ¢è¡Œé¢„å¤„ç†
    wrap_limit = V_WRAP_LIMIT if is_vertical else H_WRAP_LIMIT
    process_srt_wrapping(TRANS_SRT, WRAPPED_SRT, wrap_limit)

    # 3. æ»¤é•œé“¾æ„å»º
    # [A] ç¼©æ”¾ä¸è¡¥é»‘è¾¹é€»è¾‘ï¼šforce_original_aspect_ratio=decrease ç¡®ä¿ä¸æ‹‰ä¼¸ï¼Œpad å±…ä¸­è¡¥é½
    filter_chain = (
        f"scale={target_w}:{target_h}:force_original_aspect_ratio=decrease,"
        f"pad={target_w}:{target_h}:(ow-iw)/2:(oh-ih)/2"
    )

    # [B] æ ·å¼åº”ç”¨ (åŸºäº target_h è®¡ç®—ç¼©æ”¾ï¼Œç¡®ä¿åœ¨ 1080p/1920p ä¸‹å­—ä½“å¤§å°æ’å®š)
    if is_vertical:
        d_trans_size = int(V_TRANS_FONT_SIZE * (target_h / 1920.0))
        d_margin_v = int(V_TRANS_MARGIN_V * (target_h / 1920.0))
        trans_style = build_style(d_trans_size, TRANS_FONT_NAME, COLOR_ORANGE, COLOR_BLACK, 0, V_TRANS_BACK_COLOR, d_margin_v, margin_lr=40)
        
        filter_chain += f",subtitles={WRAPPED_SRT}:force_style='{trans_style}'"
    else:
        d_src_size = int(H_SRC_FONT_SIZE * (target_h / 1080.0))
        d_trans_size = int(H_TRANS_FONT_SIZE * (target_h / 1080.0))
        d_src_margin = int(H_SRC_MARGIN_V * (target_h / 1080.0))
        d_trans_margin = int(H_TRANS_MARGIN_V * (target_h / 1080.0))

        src_style = build_style(d_src_size, FONT_NAME, COLOR_WHITE, COLOR_BLACK, 2.5, '&H66000000', d_src_margin)
        trans_style = build_style(d_trans_size, TRANS_FONT_NAME, COLOR_ORANGE, COLOR_BLACK, 3.5, '&H80000000', d_trans_margin)
        
        filter_chain += f",subtitles={SRC_SRT}:force_style='{src_style}',subtitles={WRAPPED_SRT}:force_style='{trans_style}'"
        #filter_chain += f"subtitles={WRAPPED_SRT}:force_style='{trans_style}'"

    # [C] Logo å¤„ç†
    has_logo = os.path.exists(LOGO_PATH)
    if has_logo:
        logo_w = int(target_w * (0.18 if is_vertical else 0.12))
        # è¿™é‡Œçš„ [v_main] æ˜¯ä¸ºäº†å°†å‰é¢çš„æ»¤é•œç»“æœå‘½åï¼Œæ–¹ä¾¿ overlay å¼•ç”¨
        filter_complex = f"[0:v]{filter_chain}[v_main];[1:v]scale={logo_w}:-1[logo];[v_main][logo]overlay=W-w-25:25"
    else:
        filter_complex = f"[0:v]{filter_chain}"

    # 4. FFmpeg å‘½ä»¤æ„å»º
    ffmpeg_cmd = ['ffmpeg', '-y', '-i', video_file]
    if has_logo:
        ffmpeg_cmd.extend(['-i', LOGO_PATH])
    
    ffmpeg_cmd.extend(['-filter_complex', filter_complex])

    # GPU åŠ é€Ÿå¤„ç†
    #gpu_active = load_key("ffmpeg_gpu") if "load_key" in globals() else check_gpu_available()
    #if gpu_active:
    #    ffmpeg_cmd.extend(['-c:v', 'h264_nvenc', '-preset', 'p4', '-cq', '23'])
    #else:
    ffmpeg_cmd.extend(['-c:v', 'libx264', '-preset', 'veryfast', '-crf', '23'])

    ffmpeg_cmd.extend([
        '-c:a', 'copy',
        '-pix_fmt', 'yuv420p',
        '-movflags', '+faststart',
        OUTPUT_VIDEO
    ])

    # 5. æ‰§è¡Œæ¸²æŸ“
    rprint("ğŸš€ æ­£åœ¨æ¸²æŸ“ï¼Œè¯·ç¨å€™...")
    start_time = time.time()
    try:
        subprocess.run(ffmpeg_cmd, check=True)
        rprint(f"\nâœ… å®Œæˆ! è€—æ—¶: {time.time() - start_time:.2f}s")
        rprint(f"ğŸ“ è¾“å‡ºåˆ†è¾¨ç‡: {target_w}x{target_h}")
        rprint(f"ğŸ“ æ–‡ä»¶ä½ç½®: [bold green]{OUTPUT_VIDEO}[/bold green]")
    except subprocess.CalledProcessError as e:
        rprint(f"\nâŒ å‡ºé”™: {e}")

if __name__ == "__main__":
    merge_subtitles_to_video()
