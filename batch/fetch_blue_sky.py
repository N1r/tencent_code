import requests
import pandas as pd
import os
import logging
from tqdm import tqdm

# ============= 1. ÈÖçÁΩÆÂå∫Âüü =============

# Êó•ÂøóÈÖçÁΩÆ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

CONFIG = {
    # ÁõÆÊ†á Bluesky Ë¥¶Âè∑
    'TARGETS': [
        "acyn.bsky.social",
        "atrupar.com",
        "ronfilipkowski.bsky.social",
        "patriottakes.bsky.social",
        "meidastouch.bsky.social",
        "kamalahq.bsky.social",
        "waltermasterson.bsky.social",
        "thegoodliars.bsky.social",
    ],

    'CHECK_LIMIT': 10,  # ÊØè‰∏™Ë¥¶Âè∑Ê£ÄÊü•ÊúÄËøë 50 Êù°
    'OUTPUT_FILE': 'tasks_setting.xlsx'  # ÁõÆÊ†á Excel Êñá‰ª∂Âêç
}

# Ë°®Â§¥ÁªìÊûÑÔºà‰∏•Ê†ºÂØπÂ∫îÊà™ÂõæÔºâ
COLUMNS = [
    'Video File', 
    'title', 
    'description', 
    'viewCount', 
    'channel_name', 
    'duration', 
    'Source Language', 
    'Target Language', 
    'Dubbing', 
    'Status'
]

# ============= 2. Bluesky ÊäìÂèñÈÄªËæë =============

class BlueskyFetcher:
    def __init__(self):
        self.api_root = "https://public.api.bsky.app/xrpc"

    def resolve_handle(self, handle):
        """Ëß£ÊûêÁî®Êà∑Âêç"""
        try:
            url = f"{self.api_root}/com.atproto.identity.resolveHandle"
            res = requests.get(url, params={"handle": handle}, timeout=10)
            if res.status_code == 200:
                return res.json().get("did")
        except:
            return None
        return None

    def get_latest_videos(self, handle, limit=50):
        """Ëé∑ÂèñËßÜÈ¢ëÂπ∂Ê†ºÂºèÂåñ‰∏∫ÁõÆÊ†áÁªìÊûÑ"""
        did = self.resolve_handle(handle)
        if not did:
            return []

        url = f"{self.api_root}/app.bsky.feed.getAuthorFeed"
        params = {
            "actor": did,
            "limit": limit,
            "filter": "posts_with_video" 
        }

        try:
            res = requests.get(url, params=params, timeout=15)
            data = res.json()
            if "feed" not in data:
                return []
            
            rows = []
            for item in data["feed"]:
                post = item.get("post", {})
                record = post.get("record", {})
                
                # 1. ÁîüÊàêÈìæÊé• (Video File)
                uri = post.get("uri", "")
                if not uri: continue
                post_id = uri.split("/")[-1]
                video_link = f"https://bsky.app/profile/{handle}/post/{post_id}"
                
                # 2. Â§ÑÁêÜÊñáÊú¨ (Title / Description)
                raw_text = record.get("text", "")
                clean_title = raw_text.replace("\n", " ").strip()[:60] # Ê†áÈ¢òÂèñÂâç60Â≠ó
                if not clean_title:
                    clean_title = f"Bluesky_Video_{post_id}"
                
                # 3. Ëé∑ÂèñÁÇπËµûÊï∞‰Ωú‰∏∫ viewCount ÁöÑÊõø‰ª£ (BlueskyÊó†Êí≠ÊîæÈáè)
                like_count = post.get("likeCount", 0)

                # 4. ÊûÑÈÄ†Á¨¶Âêà tasks_setting.xlsx ÁöÑË°åÊï∞ÊçÆ
                row = {
                    'Video File': video_link,
                    'title': clean_title,
                    'description': raw_text,
                    'viewCount': like_count,      # Áî®ÁÇπËµûÊï∞Â°´ÂÖÖ
                    'channel_name': handle,       # È¢ëÈÅìÂêç
                    'duration': 0,                # APIÊó†Ê≥ïËé∑ÂèñÊó∂ÈïøÔºåÂ°´0
                    'Source Language': 'en',
                    'Target Language': 'ÁÆÄ‰Ωì‰∏≠Êñá',
                    'Dubbing': 0,
                    'Status': ''                  # ÁïôÁ©∫
                }
                rows.append(row)
            
            return rows
            
        except Exception as e:
            logger.error(f"Error fetching {handle}: {e}")
            return []

# ============= 3. ÂêàÂπ∂‰∏é‰øùÂ≠òÈÄªËæë (Excel) =============

def merge_and_save_excel(new_data):
    filename = CONFIG['OUTPUT_FILE']
    
    if not new_data:
        print("‚ö†Ô∏è Êú¨Ê¨°Êú™ÊäìÂèñÂà∞Êï∞ÊçÆ„ÄÇ")
        return

    # ËΩ¨‰∏∫ DataFrame
    new_df = pd.DataFrame(new_data)
    
    # Á°Æ‰øùÂàóÈ°∫Â∫èÊ≠£Á°Æ
    for col in COLUMNS:
        if col not in new_df.columns:
            new_df[col] = "" # Ë°•ÂÖ®Áº∫Â§±Âàó
    new_df = new_df[COLUMNS] # ÈáçÊéíÈ°∫Â∫è

    if os.path.exists(filename):
        try:
            # ËØªÂèñÊóß Excel
            old_df = pd.read_excel(filename)
            original_len = len(old_df)
            
            # ÂêàÂπ∂
            combined_df = pd.concat([old_df, new_df], ignore_index=True)
            
            # ÂéªÈáçÔºöÊ†πÊçÆ 'Video File' ÂàóÂà§Êñ≠
            # keep='first' ‰øùÁïôÊóßÁöÑËÆ∞ÂΩïÔºàËøôÊ†∑ Status Áä∂ÊÄÅ‰∏ç‰ºöË¢´Ë¶ÜÁõñÔºâ
            final_df = combined_df.drop_duplicates(subset=['Video File'], keep='first')
            
            added_count = len(final_df) - original_len
            print(f"üîÑ Êõ¥Êñ∞ÂÆåÊàêÔºöÂ∫ì‰∏≠ÂéüÊúâ {original_len} Êù°ÔºåÊñ∞Â¢û {added_count} Êù°„ÄÇ")
            
        except Exception as e:
            print(f"‚ö†Ô∏è ËØªÂèñÊóß Excel Â§±Ë¥• ({e})ÔºåÂ∞ÜÂàõÂª∫Êñ∞Êñá‰ª∂„ÄÇ")
            final_df = new_df
            print(f"üÜï ÂàõÂª∫Êñ∞‰ªªÂä°Êñá‰ª∂ÔºåÂÖ± {len(final_df)} Êù°„ÄÇ")
    else:
        final_df = new_df
        print(f"üÜï ÂàõÂª∫Êñ∞‰ªªÂä°Êñá‰ª∂ÔºåÂÖ± {len(final_df)} Êù°„ÄÇ")

    # ‰øùÂ≠ò‰∏∫ Excel
    try:
        final_df.to_excel(filename, index=False)
        print(f"‚úÖ Êñá‰ª∂Â∑≤‰øùÂ≠òËá≥: {filename}")
    except PermissionError:
        print(f"‚ùå ‰øùÂ≠òÂ§±Ë¥•ÔºÅËØ∑ÂÖàÂÖ≥Èó≠ {filename} Êñá‰ª∂ÂÜçËøêË°åËÑöÊú¨ÔºÅ")

# ============= 4. ‰∏ªÁ®ãÂ∫è =============

def main():
    fetcher = BlueskyFetcher()
    all_videos = []
    
    print(f"üöÄ ÂºÄÂßãÊâ´Êèè Bluesky -> {CONFIG['OUTPUT_FILE']}")
    
    with tqdm(total=len(CONFIG['TARGETS'])) as pbar:
        for user in CONFIG['TARGETS']:
            pbar.set_description(f"Êâ´Êèè {user}")
            videos = fetcher.get_latest_videos(user, limit=CONFIG['CHECK_LIMIT'])
            all_videos.extend(videos)
            pbar.update(1)

    print("-" * 50)
    merge_and_save_excel(all_videos)
    print("-" * 50)

if __name__ == "__main__":
    main()