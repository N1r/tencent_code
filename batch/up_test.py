import os
import shutil
import json
import random
import yaml
import requests
import pandas as pd
import re
from datetime import datetime, timedelta, timezone
from PIL import Image, ImageDraw, ImageFont, ImageFilter
from tqdm import tqdm
from fuzzywuzzy import fuzz  # ä¿æŒåŸä»£ç çš„ fuzzywuzzyï¼Œä¹Ÿå¯ä»¥æ¢æˆ rapidfuzz

# å°è¯•å¯¼å…¥ jieba è¿›è¡Œæ™ºèƒ½åè¯è¯†åˆ«
try:
    import jieba
    import jieba.posseg as pseg
    HAS_JIEBA = True
except ImportError:
    HAS_JIEBA = False
    print("ğŸš© æç¤ºï¼šæœªå®‰è£… jiebaï¼Œå°†ä½¿ç”¨åŸºç¡€éšæœºé€»è¾‘ã€‚å»ºè®®è¿è¡Œ 'pip install jieba'")

# ==================== å…¨å±€å¸¸é‡ä¸é…ç½® ====================
OUTPUT_DIR = 'output'
COVER_SUFFIX = '.jpg'
NEW_COVER_SUFFIX = '_new.png'
TARGET_WIDTH = 1920
TARGET_HEIGHT = 1080
TAG = ['æ¯æ—¥è‹±è¯­æ–°é—», è‹±è¯­æ–°é—», è‹±è¯­å­¦ä¹ , å·æ™®, é©¬æ–¯å…‹, å’¨è¯¢ç›´é€šè½¦, ç¤¾ä¼šè§‚å¯Ÿå±€, çƒ­ç‚¹æ·±åº¦è§‚å¯Ÿ']

# API é…ç½®
API_KEY = 'sk-2hQb4lo4JuCdWWCflcN41jddIIQzhtSi78Qeb7vWOM40XSkJ'
API_BASE_URL = 'https://api.302.ai'
#API_MODEL = 'gemini-2.5-flash-lite-preview-09-2025'
API_MODEL = 'qwen3-max-2026-01-23'
#API_MODEL = 'grok-4-1-fast-non-reasoning'
# è§†è§‰è§„èŒƒ
HIGHLIGHT_COLOR = "#FFD700"  # å“ç‰Œé‡‘é»„
NORMAL_COLOR = "#FFFFFF"     # çº¯ç™½
BG_BOX_COLOR = (0, 0, 0, 230) # é»‘è‰²åŠé€æ˜èƒŒæ™¯å—
RED_ACCENT = "#E21918"       # æ ‡å¿—æ€§æ–°é—»çº¢

# è‡ªåŠ¨é€‰æ‹©å­—ä½“
def get_font_path():
    possible_fonts = [
        "/root/VideoLingo/batch/Fonts/HYWenHei-65W.ttf",
        "/usr/share/fonts/google-noto-cjk/NotoSansCJK-Bold.ttc",
        "SourceHanSansSC-Bold.otf",
        "SimHei.ttf",
        "arial.ttf"
    ]
    for fp in possible_fonts:
        if os.path.exists(fp): return fp
    return "arial.ttf"

FONT_PATH = get_font_path()
print(f"ã€ç³»ç»Ÿã€‘ä½¿ç”¨å­—ä½“: {FONT_PATH}")

# ==================== 0. æ–°å¢ï¼šä¿¡æ¯æå–å·¥å…· (æ¥è‡ªä»£ç 2) ====================

def simple_read_topic(file_path: str) -> list:
    """è¯»å– gpt_log ä¸‹çš„ summary.json è·å– topic"""
    if not os.path.exists(file_path):
        return []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        # å…¼å®¹åˆ—è¡¨æˆ–å­—å…¸ç»“æ„
        if isinstance(data, list):
            return [item['response']['topic'] for item in data if 'response' in item and 'topic' in item['response']]
        elif isinstance(data, dict) and 'response' in data and 'topic' in data['response']:
             return [data['response']['topic']]
        return []
    except Exception as e:
        print(f"âš ï¸ è¯»å– Topic å¤±è´¥: {e}")
        return []

def quick_read_srt(file_path: str) -> str:
    """æç®€è¯»å– SRT çº¯æ–‡æœ¬"""
    with open(file_path, 'r', encoding='utf-8-sig', errors='ignore') as f:
        content = f.read()
    
    # åŒ¹é…æ—¶é—´è½´çš„æ­£åˆ™
    pattern = r'\d{2}:\d{2}:\d{2},\d{3} --> \d{2}:\d{2}:\d{2},\d{3}'
    
    # ä¸€è¡Œæå®šï¼šè¿‡æ»¤ç©ºè¡Œã€æ•°å­—è¡Œã€æ—¶é—´è¡Œ
    lines = [
        line.strip() for line in content.splitlines() 
        if line.strip() and not line.strip().isdigit() and not re.match(pattern, line)
    ]
    
    return "\n".join(lines)
def find_channel_by_fuzzy_match(excel_path: str, target_title: str, min_similarity=80):
    """æ ¹æ®æ–‡ä»¶å¤¹åæ¨¡ç³ŠåŒ¹é… Excel ä¸­çš„é¢‘é“å"""
    if not os.path.exists(excel_path):
        print(f"âš ï¸ æœªæ‰¾åˆ° {excel_path}ï¼Œè·³è¿‡é¢‘é“åŒ¹é…")
        return None
    try:
        df = pd.read_excel(excel_path)
        if 'title' not in df.columns or 'channel_name' not in df.columns:
            print("âš ï¸ Excel ç¼ºå°‘ 'title' æˆ– 'channel_name' åˆ—")
            return None
        
        best_match, best_score = None, 0
        for _, row in df.iterrows():
            current_title = str(row['title'])
            # ä½¿ç”¨ fuzzywuzzy çš„ ratio
            similarity = fuzz.ratio(target_title.lower(), current_title.lower())
            if similarity > best_score and similarity >= min_similarity:
                best_score, best_match = similarity, row['channel_name']
        
        if best_match:
            # print(f"âœ… é¢‘é“åŒ¹é…æˆåŠŸï¼ˆ{best_score}%ï¼‰ï¼š'{best_match}'")
            return best_match
        else:
            return None
    except Exception as e:
        print(f"âŒ é¢‘é“åŒ¹é…å‡ºé”™: {e}")
        return None

# ==================== 1. æ™ºèƒ½é«˜äº®é€»è¾‘ (é¿å¼€è™šè¯) ====================

def get_random_noun_highlight(text):
    """æå–æ ‡é¢˜ä¸­çš„æ ¸å¿ƒåè¯å®ä½“ï¼Œé¿å¼€è™šè¯"""
    # ç§»é™¤ [é¢‘é“å] å¹²æ‰°
    clean_text = re.sub(r'\[.*?\]', '', text)
    
    if HAS_JIEBA:
        words = pseg.cut(clean_text)
        nouns = [w.word for w in words if w.flag in ['n', 'nr', 'ns', 'nt', 'nz'] and len(w.word) > 1]
        if nouns:
            return random.choice(nouns)
    
    STOP_WORDS = ["çš„", "äº†", "åœ¨", "æ˜¯", "è¢«", "å·²ç»", "ä¸ä»…", "ç”šè‡³", "è€Œä¸”"]
    parts = re.findall(r'[\u4e00-\u9fa5]{2,4}', clean_text)
    valid_parts = [p for p in parts if p not in STOP_WORDS]
    
    return random.choice(valid_parts) if valid_parts else None

# ==================== 2. å°é¢ç»˜å›¾æ ¸å¿ƒ (ç²¾å‡†å¯¹é½) ====================

def wrap_text_styled(text, font, max_width):
    lines = []
    current_line = ""
    for char in text:
        if font.getlength(current_line + char) <= max_width:
            current_line += char
        else:
            lines.append(current_line)
            current_line = char
    lines.append(current_line)
    return lines[:2] 

def draw_text_line_centered(draw, line, font, x_start, y_top, box_height, highlight_word):
    left, top, right, bottom = font.getbbox(line)
    text_height = bottom - top
    vertical_center_offset = (box_height - text_height) // 2 - top
    draw_y = y_top + vertical_center_offset

    if not highlight_word or highlight_word not in line:
        draw.text((x_start, draw_y), line, font=font, fill=NORMAL_COLOR)
        return

    parts = line.split(highlight_word, 1)
    current_x = x_start
    draw.text((current_x, draw_y), parts[0], font=font, fill=NORMAL_COLOR)
    current_x += font.getlength(parts[0])
    draw.text((current_x, draw_y), highlight_word, font=font, fill=HIGHLIGHT_COLOR)
    current_x += font.getlength(highlight_word)
    draw.text((current_x, draw_y), parts[1], font=font, fill=NORMAL_COLOR)

def cover_making(image_path, output_path, translated_text):
    try:
        hl_word = get_random_noun_highlight(translated_text)
        clean_title = re.sub(r'\[.*?\]', '', translated_text)

        bg = Image.open(image_path).convert('RGBA')
        bg = bg.resize((TARGET_WIDTH, TARGET_HEIGHT), Image.Resampling.LANCZOS)
        bg = bg.filter(ImageFilter.GaussianBlur(radius=2))
        overlay = Image.new('RGBA', (TARGET_WIDTH, TARGET_HEIGHT), (0, 0, 0, 60))
        canvas = Image.alpha_composite(bg, overlay)
        draw = ImageDraw.Draw(canvas)

        tag_font = ImageFont.truetype(FONT_PATH, 45)
        tag_text = " ğŸŒ GLOBAL NEWS â€¢ æ·±åº¦ç›´å‡» "
        tag_w = tag_font.getlength(tag_text)
        draw.rectangle([0, 60, tag_w + 100, 135], fill=RED_ACCENT)
        draw.text((50, 75), tag_text, font=tag_font, fill="white")

        title_size = 140
        title_font = ImageFont.truetype(FONT_PATH, title_size)
        lines = wrap_text_styled(clean_title, title_font, TARGET_WIDTH - 300)

        box_h = title_size + 45
        line_spacing = 30
        total_h = len(lines) * box_h + (len(lines)-1) * line_spacing
        current_y = max(TARGET_HEIGHT - total_h - 130, 220)

        for line in lines:
            lw = title_font.getlength(line)
            box_l, box_r = 60, 60 + lw + 100
            draw.rectangle([box_l, current_y, box_r, current_y + box_h], fill=BG_BOX_COLOR)
            draw.rectangle([box_l, current_y, box_l + 15, current_y + box_h], fill=RED_ACCENT)
            draw_text_line_centered(draw, line, title_font, box_l + 45, current_y, box_h, hl_word)
            current_y += box_h + line_spacing

        canvas.convert('RGB').save(output_path, quality=95)
    except Exception as e:
        print(f"âŒ å°é¢å¤±è´¥ {image_path}: {e}")

# ==================== 3. API ç¿»è¯‘é€»è¾‘ (å·²å¢å¼º) ====================
#2.  å¿…é¡»åŒ…å«ã€é¢‘é“åã€‘ä½œä¸ºä¿¡æºèƒŒä¹¦æˆ–å˜²è®½å¯¹è±¡ï¼ˆå¦‚ï¼šMeidasTouchæ›çŒ›æ–™ / ç¦å…‹æ–¯ç¿»è½¦ï¼‰ã€‚

def translate_with_api(text_content: str) -> str:
    """
    æ¥æ”¶åŒ…å« é¢‘é“åã€åŸæ ‡é¢˜ã€Topic çš„ç»¼åˆå­—ç¬¦ä¸²è¿›è¡Œå¤„ç†
    """
    headers = {"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json"}
    prompt = """
# Role

ä½ æ˜¯ä¸€åè¿½æ±‚â€œé«˜ä¿¡æ¯å¯†åº¦â€çš„Bç«™å›½é™…æ—¶æ”¿åŒºèµ„æ·±ç¼–è¾‘ã€‚ä½ çš„æ ¸å¿ƒèƒ½åŠ›æ˜¯â€œé™å™ªâ€ï¼šä»å†—é•¿çš„å¤–åª’å­—å¹•ä¸­ï¼Œæç‚¼å‡ºæœ€å…·ä½“ã€æœ€åç›´è§‰ã€æˆ–æœ€å…·ç»†èŠ‚æ„Ÿçš„é€»è¾‘é“¾æ¡ï¼Œè€Œéç®€å•çš„æ¦‚æ‹¬ã€‚
# Input Data

- åŸæ ‡é¢˜ï¼š{folder_name}
- è®¨è®ºä¸»é¢˜ï¼š{topic_list}
- å­—å¹•å†…å®¹ï¼š{srt_list}

# Construction Rules (æ ¸å¿ƒä¿®æ”¹ç‚¹)

1. **æ‹’ç»ç¬¼ç»Ÿï¼Œå¿…é¡»å…·ä½“ï¼ˆGranularityï¼‰ï¼š**

   - âŒ é”™è¯¯ï¼šç—›æ–¥ç‰¹æœ—æ™®çš„æ”¿ç­–å¾ˆè’è°¬
   - âœ… æ­£ç¡®ï¼šåæ§½ç‰¹æœ—æ™®â€œå¸ç®¡æ²»å›½â€ï¼šä¸ºäº†çœæ°´æŠŠå‘å‹éƒ½æ´—å¡Œäº†
   - **æŒ‡ä»¤**ï¼šå¿…é¡»ä»å­—å¹•ä¸­æå–**å…·ä½“çš„åè¯ã€æ•°æ®ã€æ¯”å–»æˆ–ç‰¹å®šäº‹ä»¶**è¿›æ ‡é¢˜ã€‚
2. **æ ¼å¼è§„èŒƒï¼š**

   - æ ¼å¼: å…·è±¡åŒ–ç»†èŠ‚/æ ¸å¿ƒé€»è¾‘/ç»å…¸è¯­å¥.
   - ä»…è¾“å‡ºä¸€è¡Œï¼Œä¸¥ç¦åŠè§’ç¬¦å·ï¼ˆ: / \ ? * " < > |ï¼‰ï¼Œå­—æ•°25-35å­—ã€‚

# Workflow
1. åˆ†æå­—å¹•ï¼Œæ‰¾åˆ°æœ€å…·äº‰è®®æˆ–æœ€çŠ€åˆ©çš„ä¸€å¥è¯ã€‚
2. è¾“å‡ºç»“æœã€‚

# Output Goal

ç”Ÿæˆä¸€ä¸ª **â€œçœ‹äº†æ ‡é¢˜å°±çŸ¥é“è§†é¢‘è®²äº†ä»€ä¹ˆå…·ä½“äº‹â€** çš„æ–‡ä»¶åï¼Œè€Œä¸æ˜¯ç¬¼ç»Ÿçš„æ ‡é¢˜å…šã€‚
"""
    data = {
        "model": API_MODEL,
        "messages": [
            {"role": "system", "content": prompt},
            {"role": "user", "content": text_content}
        ],
    }
    try:
        response = requests.post(f"{API_BASE_URL}/v1/chat/completions", headers=headers, json=data, timeout=30)
        return response.json()["choices"][0]["message"]["content"].strip()
    except Exception as e:
        print(f"API Error: {e}")
        return None

# ==================== 4. ä¸šåŠ¡å¤„ç†é€»è¾‘ (æ•´åˆäº† Topic å’Œ Channel) ====================

def generate_titles(video_paths: list) -> tuple:
    titles, translated_texts = [], []
    
    print(f"ğŸ” å¼€å§‹ç”Ÿæˆæ ‡é¢˜ï¼Œå…± {len(video_paths)} ä¸ªè§†é¢‘...")
    
    for video_path in video_paths:
        folder_path = os.path.dirname(video_path)
        folder_name = os.path.basename(folder_path)
        
        # --- æ•´åˆé€»è¾‘å¼€å§‹ ---
        # 1. è·å– Topic
        json_path = os.path.join(folder_path, 'gpt_log', 'summary.json')
        topic_list = simple_read_topic(json_path)
        srt_path = os.path.join(folder_path, 'trans.srt')
        srt_list = quick_read_srt(srt_path)
        #print(srt_list)
        # 2. è·å– Channel Name
        channel_name = find_channel_by_fuzzy_match('tasks_setting.xlsx', folder_name) or "ç²¾é€‰æ–°é—»"
        
        # 3. æ„é€ å‘é€ç»™ API çš„å†…å®¹
        #prompt_content = f"é¢‘é“åä¸ºï¼š{channel_name}\nåŸæ ‡é¢˜ä¸º:{folder_name}\nå†…å®¹ä¸»é¢˜ä¸º:{topic_list}å®Œæ•´å­—å¹•: {srt_list}"
        prompt_content = f"é¢‘é“åä¸ºï¼š{channel_name}\nåŸæ ‡é¢˜ä¸º:{folder_name}\nå†…å®¹ä¸»é¢˜ä¸º:{topic_list}å®Œæ•´å­—å¹•: {srt_list}"

        # print(f"  > å¤„ç†: {folder_name} | é¢‘é“: {channel_name}")
        # --- æ•´åˆé€»è¾‘ç»“æŸ ---

        # è°ƒç”¨ API
        translated = translate_with_api(prompt_content) or folder_name
        
        # ç»“æœå¤„ç†
        translated_texts.append(translated)
        clean_t = re.sub(r'\[.*?\]', '', translated)
        
        # æœ€ç»ˆæ ‡é¢˜åŠ ä¸Šé¢‘é“ååç¼€ (å¦‚æœéœ€è¦)
        final_title = f"[ä¸­è‹±]{clean_t}"
        titles.append(final_title)
        
        print(f" âœ… ç”Ÿæˆæ ‡é¢˜: {final_title}")

    return titles, translated_texts

# ==================== é…ç½®ï¼šæ–‡æ¡ˆä¸æ ‡ç­¾ (å˜²è®½/åƒç“œé£æ ¼) ====================

# ç®€ä»‹æ¨¡æ¿åº“ï¼ˆéšæœºæŠ½å–ï¼Œä¿æŒæ–°é²œæ„Ÿï¼Œé¿å…æŸ¥é‡ï¼‰
DESC_TEMPLATES = [
    """ã€ä¸­è‹±åŒè¯­ã€‘å¸¦ä½ çœ‹æ‡‚ç¾å¼â€œæ°‘ä¸»â€çš„ç¿»è½¦ç°åœº ğŸ¤¡
ğŸ‘‰ æŒ–æ˜ç¾åª’å†…è®§å®å½•ï¼Œç›´å‡»ä¸¤å…šâ€œäº’å’¬â€æœ€å‰çº¿ã€‚
ğŸš« æ‹’ç»è¥¿æ–¹æ»¤é•œï¼Œè¿˜åŸæœ€çœŸå®çš„ç¾å›½ã€‚
---------------------------------------
ğŸ“¢ å£°æ˜ï¼šè§†é¢‘ç´ ææºè‡ªå¤–ç½‘ï¼Œä»…ä¾›æ‰¹åˆ¤æ€§ç ”ç©¶ä¸è¯­è¨€å­¦ä¹ ã€‚
ğŸ”¥ æ¯æ—¥æ›´æ–°ç¾å¸è’è¯äº‹ï¼Œå–œæ¬¢è¯·ã€ç‚¹èµ+æŠ•å¸ã€‘æ”¯æŒï¼Œè¿™å¯¹æˆ‘çœŸçš„å¾ˆé‡è¦ï¼""",

    """âš¡ï¸ é«˜èƒ½é¢„è­¦ï¼šç¾å¼æ”¿å›å¤§å‹â€œåŒæ ‡â€ä¸â€œç ´é˜²â€ç°åœº
ä¸ä»…æ˜¯è‹±è¯­å¬åŠ›ç´ æï¼Œæ›´æ˜¯è§‚å¯Ÿè¥¿æ–¹ç¤¾ä¼šæ’•è£‚çš„ç»ä½³çª—å£ã€‚
çœ‹æ‡‚ç‹ï¼ˆå·æ™®ï¼‰å¦‚ä½•æ•´æ´»ï¼Œçœ‹è‡ªç”±æ´¾å¦‚ä½•æ— èƒ½ç‹‚æ€’ã€‚
---------------------------------------
ğŸ’¡ å…³æ³¨é¢‘é“ï¼Œæ¯å¤©ä¸‰åˆ†é’Ÿï¼Œç”¨åƒç“œçš„å¿ƒæ€çœ‹ä¸–ç•Œã€‚
âœ¨ ä½ çš„ã€ä¸€é”®ä¸‰è¿ã€‘æ˜¯æ›´æ–°çš„æœ€å¤§åŠ¨åŠ›ï¼""",

    """ğŸ‡ºğŸ‡¸ æ¬¢è¿æ¥åˆ°â€œè‡ªç”±ç¾åˆ©åšâ€çš„é­”å¹»ç°å®ä¸»ä¹‰ç‰‡åœºã€‚
è¿™é‡Œæœ‰æœ€çŠ€åˆ©çš„åª’ä½“åæ§½ï¼Œæœ€ç›´æ¥çš„æ”¿å®¢äº’æ€¼ã€‚
ä¸­è‹±åŒè¯­å­—å¹•ç²¾æ ¡ï¼Œç¡®ä¿ä½ ä¸é”™è¿‡æ¯ä¸€ä¸ªâ€œååœºé¢â€ã€‚
---------------------------------------
ğŸ¯ æ ¸å¿ƒçœ‹ç‚¹ï¼šç‰¹æœ—æ™® | å…±å’Œå…šå†…ä¹± | åª’ä½“æ­ç§˜
ğŸ’¬ è¯„è®ºåŒºä»¥æ­¤ä¸ºæ®ï¼Œæ¬¢è¿å„è·¯å¤§ç¥æŒ‡ç‚¹æ±Ÿå±±ã€‚
â¤ï¸ è§‰å¾—æœ‰æ„æ€è¯·é•¿æŒ‰ç‚¹èµï¼Œæ„Ÿè°¢æ”¯æŒï¼"""
]

# è¡¥å……æ ‡ç­¾ï¼ˆé«˜çƒ­åº¦å…³é”®è¯ï¼‰
EXTRA_TAGS = "ç‰¹æœ—æ™®,ç¾å›½å¤§é€‰,å…±å’Œå…š,æ°‘ä¸»å…š,ç¾å¼ç¬‘è¯,åŒè¯­å­—å¹•,å¬åŠ›,å›½é™…æ—¶äº‹,åƒç“œ"

# ==================== æ ¸å¿ƒé€»è¾‘ï¼šYAML ç”Ÿæˆ ====================

def split_and_create_yaml(videos, covers, titles, dtimes, paid_ratio=0.1):
    """
    å°†è§†é¢‘åˆ—è¡¨éšæœºåˆ’åˆ†ä¸ºå…è´¹/ä»˜è´¹å†…å®¹ï¼Œå¹¶ç”Ÿæˆå¯¹åº”çš„ä¸Šä¼  YAML é…ç½®æ–‡ä»¶
    """
    total = len(videos)
    indices = list(range(total))
    random.shuffle(indices) # æ‰“ä¹±é¡ºåº
    
    # è®¡ç®—åˆ†å‰²ç‚¹
    split_point = int(total * (1 - paid_ratio))
    
    # --- å†…éƒ¨å‡½æ•°ï¼šå†™å…¥ YAML ---
    def write_yaml(sub_v, sub_c, sub_t, sub_dt, filename, is_paid):
        streamers = {}
        
        for i, (v, c, t, dt) in enumerate(zip(sub_v, sub_c, sub_t, sub_dt)):
            # 1. éšæœºé€‰æ‹©ç®€ä»‹æ¨¡æ¿
            base_desc = random.choice(DESC_TEMPLATES)
            
            # 2. ç»„åˆæœ€ç»ˆç®€ä»‹ (å°†æ ‡é¢˜æ”¾åœ¨ç¬¬ä¸€è¡Œï¼Œåˆ©äº SEO å’Œç”¨æˆ·å¿«é€Ÿé¢„è§ˆ)
            final_desc = f"â–º æœ¬æœŸçœ‹ç‚¹ï¼š{t}\n\n{base_desc}"
            
            # 3. å¤„ç†æ ‡ç­¾ (åˆå¹¶ Global TAG å’Œ EXTRA_TAGS)
            # å‡è®¾å…¨å±€ TAG[0] æ˜¯ç±»ä¼¼ "æ¯æ—¥è‹±è¯­æ–°é—»,..." çš„å­—ç¬¦ä¸²
            base_tag = TAG[0] if (type(TAG) is list and len(TAG) > 0) else ""
            combined_tag = f"{base_tag},{EXTRA_TAGS}"
            
            # å»é‡ã€å»ç©ºã€é™åˆ¶æ•°é‡ (Bç«™é™åˆ¶æ ‡ç­¾æ•°ï¼Œé€šå¸¸å–å‰12ä¸ª)
            tag_list = list(set([x.strip() for x in combined_tag.split(',') if x.strip()]))
            final_tag = ",".join(tag_list[:12])

            # 4. æ„é€ å•ä¸ªè§†é¢‘çš„é…ç½®é¡¹
            entry = {
                "copyright": 1,           # 1=è‡ªåˆ¶ (ç¿»è¯‘äºŒåˆ›é€šå¸¸æŠ•è‡ªåˆ¶)
                "source": None,           # è‡ªåˆ¶æ— éœ€ source
                "tid": 208,               # åˆ†åŒºID (208=èµ„è®¯-ç¯çƒ/æ—¶æ”¿ï¼Œè¯·æ ¹æ®éœ€è¦è°ƒæ•´)
                "cover": c, 
                "title": t,
                "desc": final_desc,
                "tag": final_tag,
                "dtime": dt,              # å®šæ—¶å‘å¸ƒæ—¶é—´æˆ³
                "open-elec": 1,           # å¼€å¯å……ç”µ
            }
            
            # å¦‚æœæ˜¯ä»˜è´¹å†…å®¹ï¼Œæ·»åŠ ä»˜è´¹å­—æ®µ
            if is_paid:
                entry.update({
                    "charging_pay": 1, 
                    "upower_level_id": "1212996740244948080" # ğŸ”´ è¯·ç¡®è®¤è¿™æ˜¯æ‚¨çš„å……ç”µè®¡åˆ’ ID
                })
                
            streamers[v] = entry

        # 5. å†™å…¥æ–‡ä»¶
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                # allow_unicode=True ä¿è¯ä¸­æ–‡æ­£å¸¸æ˜¾ç¤ºï¼Œsort_keys=False ä¿æŒå­—æ®µé¡ºåº
                yaml.dump({"submit": "App", "streamers": streamers}, f, allow_unicode=True, sort_keys=False)
            print(f"ğŸ“„ å·²ç”Ÿæˆé…ç½®æ–‡ä»¶: {filename} (åŒ…å« {len(sub_v)} ä¸ªè§†é¢‘)")
        except Exception as e:
            print(f"âŒ å†™å…¥ YAML å¤±è´¥ ({filename}): {e}")

    # --- æ‰§è¡Œåˆ†å‰²ä¸å†™å…¥ ---
    
    # åˆ’åˆ†ç´¢å¼•
    f_idx = indices[:split_point] # å…è´¹éƒ¨åˆ†ç´¢å¼•
    p_idx = indices[split_point:] # ä»˜è´¹éƒ¨åˆ†ç´¢å¼•
    
    # ç”Ÿæˆå…è´¹å†…å®¹çš„ YAML
    write_yaml(
        [videos[i] for i in f_idx], 
        [covers[i] for i in f_idx], 
        [titles[i] for i in f_idx], 
        [dtimes[i] for i in f_idx], 
        'free_content.yaml', 
        False
    )
    
    # ç”Ÿæˆä»˜è´¹å†…å®¹çš„ YAML (å¦‚æœæœ‰çš„è¯)
    if p_idx:
        write_yaml(
            [videos[i] for i in p_idx], 
            [covers[i] for i in p_idx], 
            [titles[i] for i in p_idx], 
            [dtimes[i] for i in p_idx], 
            'paid_content.yaml', 
            True
        )
# ==================== 5. ä¸»ç¨‹åº ====================

def main():
    # æŸ¥æ‰¾è§†é¢‘
    videos = []
    for root, _, files in os.walk(OUTPUT_DIR):
        if 'output_sub.mp4' in files:
            videos.append(os.path.join(root, 'output_sub.mp4'))
    
    if not videos:
        print("âŒ æœªå‘ç° output_sub.mp4 æ–‡ä»¶")
        return

    # 1. æ ‡é¢˜ä¸ç¿»è¯‘ (æ ¸å¿ƒé€»è¾‘å·²æ›´æ–°)
    bilibili_titles, translated_raw = generate_titles(videos)
    
    # 2. å®šæ—¶å‘å¸ƒæ—¶é—´ (æ˜å¤©å¼€å§‹ï¼Œæ¯éš”1.5å°æ—¶ä¸€ä¸ª)
    start_time = datetime.now(timezone(timedelta(hours=8))).replace(hour=8, minute=0, second=0) + timedelta(days=1)
    dtimes = [int((start_time + timedelta(minutes=45*i)).timestamp()) for i in range(len(videos))]

    # 3. å¤„ç†å°é¢
    new_covers = []
    for vid, trans in tqdm(zip(videos, translated_raw), total=len(videos), desc="ç”Ÿæˆå°é¢"):
        folder = os.path.dirname(vid)
        # å¯»æ‰¾åŸå›¾
        raw_jpg = next((os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.jpg')), None)
        if raw_jpg:
            new_c = raw_jpg.replace('.jpg', NEW_COVER_SUFFIX)
            cover_making(raw_jpg, new_c, trans)
            new_covers.append(new_c)
        else:
            new_covers.append("") # å ä½

    # 4. ç”Ÿæˆ YAML
    split_and_create_yaml(videos, new_covers, bilibili_titles, dtimes)
    print("âœ¨ å…¨éƒ¨æµç¨‹å®Œæˆï¼ŒYAML å·²ç”Ÿæˆã€‚")

if __name__ == "__main__":
    main()
