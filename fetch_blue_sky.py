import requests
import pandas as pd
import os
import logging
import time
import random
from tqdm import tqdm
from googletrans import Translator

# ============= 1. é…ç½®åŒºåŸŸ =============

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

CONFIG = {
    'TARGETS': [
        "acyn.bsky.social",
        "atrupar.com",
        "thedailyshow.com",
        "briantylercohen.bsky.social",
        "thebulwark.com",
        "anthonyvslater.bsky.social",
        "latenightercom.bsky.social",
        "cwebbonline.com",
        "reuters.com",        
    ],
    'CHECK_LIMIT': 10, 
    'OUTPUT_FILE': 'batch/tasks_setting.xlsx',
    'ENABLE_TRANSLATION': False,  # æ˜¯å¦å¼€å¯ç¿»è¯‘åŠŸèƒ½
    'TARGET_LANG': 'zh-cn'       # ç¿»è¯‘ç›®æ ‡è¯­è¨€
}

# æœ€ç»ˆä¿å­˜çš„åˆ—ç»“æž„
COLUMNS = [
    'Video File', 
    'title', 
    'rawtext',
    'translated_text', # æ–°å¢žç¿»è¯‘ç»“æžœåˆ—
    'Publish Date',    
    'Replies',         
    'Reposts',         
    'viewCount',       
    'channel_name', 
    'duration', 
    'Source Language', 
    'Target Language', 
    'Dubbing', 
    'Status'
]

# ============= 2. Bluesky æŠ“å–é€»è¾‘ =============

class BlueskyFetcher:
    def __init__(self):
        self.api_root = "https://public.api.bsky.app/xrpc"

    def resolve_handle(self, handle):
        try:
            url = f"{self.api_root}/com.atproto.identity.resolveHandle"
            res = requests.get(url, params={"handle": handle}, timeout=10)
            if res.status_code == 200:
                return res.json().get("did")
        except:
            return None
        return None

    def get_latest_videos(self, handle, limit=50):
        did = self.resolve_handle(handle)
        if not did: return []

        url = f"{self.api_root}/app.bsky.feed.getAuthorFeed"
        params = {"actor": did, "limit": limit, "filter": "posts_with_video"}

        try:
            res = requests.get(url, params=params, timeout=15)
            data = res.json()
            if "feed" not in data: return []
            
            rows = []
            for item in data["feed"]:
                post = item.get("post", {})
                record = post.get("record", {})
                embed = post.get("embed", {})
                
                uri = post.get("uri", "")
                if not uri: continue
                post_id = uri.split("/")[-1]
                video_link = f"https://bsky.app/profile/{handle}/post/{post_id}"
                
                raw_text = record.get("text", "")
                clean_title = raw_text.replace("\n", " ").strip()[:50]
                
                raw_date = post.get("indexedAt", "")
                publish_date = raw_date.replace("T", " ").split(".")[0] if raw_date else ""
                
                # å°è¯•èŽ·å–è§†é¢‘æ—¶é•¿ (duration)
                v_duration = 0
                if embed.get('$type') == 'app.bsky.embed.video#view':
                    v_duration = embed.get('video', {}).get('duration', 0)

                rows.append({
                    'Video File': video_link,
                    'title': clean_title if clean_title else f"Video_{post_id}",
                    'rawtext': raw_text,
                    #'translated_text': "", # åˆå§‹ä¸ºç©ºï¼Œå¾…åŽç»­ç¿»è¯‘
                    'Publish Date': publish_date,
                    'Replies': post.get("replyCount", 0),
                    'Reposts': post.get("repostCount", 0),
                    'viewCount': post.get("likeCount", 0),
                    'channel_name': handle,
                    'duration': v_duration,
                    'Source Language': 'en',
                    'Target Language': 'ç®€ä½“ä¸­æ–‡',
                    'Dubbing': 0,
                    'Status': ''
                })
            return rows
        except Exception as e:
            logger.error(f"Error fetching {handle}: {e}")
            return []

# ============= 3. ç¿»è¯‘é€»è¾‘ =============

def perform_translation(df):
    """å¯¹ DataFrame ä¸­æœªç¿»è¯‘çš„ rawtext è¿›è¡Œç¿»è¯‘"""
    translator = Translator()
    # ç­›é€‰ï¼šrawtext æœ‰å†…å®¹ ä¸” translated_text ä¸ºç©ºçš„è¡Œ
    mask = df['rawtext'].notna() & (df['translated_text'].astype(str).str.strip() == "")
    to_translate = df[mask]

    if to_translate.empty:
        return df

    print(f"ðŸŒ æ­£åœ¨ç¿»è¯‘ {len(to_translate)} æ¡æ–°å†…å®¹...")
    for idx in tqdm(to_translate.index, desc="ç¿»è¯‘è¿›åº¦"):
        try:
            text = str(df.at[idx, 'rawtext']).strip()
            if text:
                result = translator.translate(text, dest=CONFIG['TARGET_LANG'])
                df.at[idx, 'translated_text'] = result.text
                time.sleep(random.uniform(0.3, 0.8)) # éšæœºå»¶æ—¶é˜²å°
        except Exception as e:
            logger.warning(f"ç¿»è¯‘å¤±è´¥ (è¡Œ {idx}): {e}")
            continue
    return df

# ============= 4. åˆå¹¶ä¸Žä¿å­˜ =============

def merge_and_save_excel(new_data):
    filename = CONFIG['OUTPUT_FILE']
    if not new_data:
        print("âš ï¸ æœªå‘çŽ°æ–°è§†é¢‘ã€‚")
        return

    new_df = pd.DataFrame(new_data)
    for col in COLUMNS:
        if col not in new_df.columns: new_df[col] = ""

    if os.path.exists(filename):
        try:
            old_df = pd.read_excel(filename)
            # åˆå¹¶å¹¶æ ¹æ®é“¾æŽ¥åŽ»é‡ï¼Œä¿ç•™æ—§è®°å½•ï¼ˆä¿ç•™å·²æœ‰çš„ç¿»è¯‘å’ŒçŠ¶æ€ï¼‰
            combined_df = pd.concat([old_df, new_df], ignore_index=True)
            final_df = combined_df.drop_duplicates(subset=['Video File'], keep='first')
        except:
            final_df = new_df
    else:
        final_df = new_df

    # è§¦å‘ç¿»è¯‘åŠŸèƒ½
    if CONFIG['ENABLE_TRANSLATION']:
        final_df = perform_translation(final_df)

    # æŽ’åºï¼šæŒ‰å‘å¸ƒæ—¶é—´å€’åº
    final_df = final_df.sort_values(by='viewCount', ascending=False)
    final_df = final_df[COLUMNS]

    try:
        os.makedirs(os.path.dirname(filename), exist_ok=True)
        final_df.to_excel(filename, index=False)
        print(f"âœ… å¤„ç†å®Œæˆï¼æ–‡ä»¶ä¿å­˜è‡³: {filename}")
    except PermissionError:
        print(f"âŒ é”™è¯¯ï¼šè¯·å…ˆå…³é—­ Excel æ–‡ä»¶ {filename}")

# ============= 5. ä¸»ç¨‹åº =============

def main():
    fetcher = BlueskyFetcher()
    all_videos = []
    print(f"ðŸš€ å¼€å§‹ä»»åŠ¡: æ‰«æ -> ç¿»è¯‘ -> å¯¼å‡º")
    
    for user in CONFIG['TARGETS']:
        videos = fetcher.get_latest_videos(user, limit=CONFIG['CHECK_LIMIT'])
        all_videos.extend(videos)

    merge_and_save_excel(all_videos)

if __name__ == "__main__":
    main()